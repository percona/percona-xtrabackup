--source include/big_test.inc
--source include/have_debug.inc
--source include/have_innodb_16k.inc

SET GLOBAL innodb_compression_level = 0;
CREATE TABLE t1 (j1 JSON) ENGINE=InnoDB ROW_FORMAT=compressed;
SHOW CREATE TABLE t1;
# must be long enough to force external storage
# also the length must be so that json_doc last "page" of last stream
# is short enough to fit on fragment page
SET @long_str = REPEAT('abcdefghijklmnopqrstuvwxyz1234', 60000);
# must be long enough to force new version (as opposed to storing diff in the undo log),
# but must be short enough to not cause complete rewrite of the blob
SET @medium_str_1 = REPEAT('a', 200);
SET @medium_str_2 = REPEAT('b', 200);
SET @json_doc = CONCAT('["', @long_str, '","', @medium_str_1 ,'" ]');

INSERT INTO t1 (j1) VALUES (@json_doc);

SELECT JSON_EXTRACT(j1, '$[1]') FROM t1;

SET GLOBAL innodb_purge_stop_now = ON;

--disable_query_log
--let i=0
while($i<50){
  UPDATE t1 SET j1 = JSON_REPLACE(j1, '$[1]', @medium_str_2);
  UPDATE t1 SET j1 = JSON_REPLACE(j1, '$[1]', @medium_str_1);
  --inc $i
}
--enable_query_log

SET GLOBAL innodb_purge_run_now = ON;

# Give it a lot of time, so that the internal time limit of wait_innodb_all_purge
# is much larger than the one provided in ./mtr --testcase-timeout=5
--let wait_timeout=3600
--source include/wait_innodb_all_purged.inc
DROP TABLE t1;
SET GLOBAL innodb_compression_level = default;

