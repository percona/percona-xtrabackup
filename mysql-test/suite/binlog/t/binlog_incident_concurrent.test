# ==== Purpose ====
#
# Verify that writing an incident log event that
# also rotates the binlog works while concurrent DML are ongoing.
#
# ==== Requirements ====
#
# R1. When the server generates an incident while there are concurrent DML
#     statements, it should not crash or lockup.
#
# ==== Implementation ====
#
# - In one session, execute a DML load for 5 seconds.
# - In another concurrent session, generate incident events 10 times per seconds,
#   for 5 seconds.
# - Verify that there are 50 binlogs and that each of them contains an Incident
#   event.
# - (Verify that it did not crash or lockup).
#
# ==== References ====
#
# Bug#35671897 Concurrent Binlog rotate and DDL commit hit safe_mutex assertion
#

--source include/have_log_bin.inc
--source include/have_myisam.inc
# Test in this file is binlog format agnostic, thus no need
# to rerun it for every format.
--source include/have_binlog_format_row.inc

call mtr.add_suppression("Non-transactional changes were not written to the binlog. An incident event has been written to the binary log which will stop the replicas.");

let $old_max_binlog_stmt_cache_size=
  query_get_value(SHOW VARIABLES LIKE "max_binlog_stmt_cache_size", Value, 1);
let $old_binlog_stmt_cache_size=
  query_get_value(SHOW VARIABLES LIKE "binlog_stmt_cache_size", Value, 1);
SET GLOBAL max_binlog_stmt_cache_size = 4096;
SET GLOBAL binlog_stmt_cache_size = 4096;


CREATE TABLE t1(c1 INT PRIMARY KEY, data TEXT(30000)) ENGINE=MyIsam;
CREATE TABLE t2 (a INT PRIMARY KEY, b VARCHAR(400)) engine=InnoDB;

delimiter %;
CREATE PROCEDURE dmlload (seconds int)
begin
  set @x=time_to_sec(current_time()) + seconds;
  repeat
    start transaction;
      insert into t2 values (2, repeat('I', 400));
    commit;
    start transaction;
      update t2 set b=repeat('Z', 400) where a=2;
    commit;
    start transaction;
      delete from t2 where a=2;
    commit;
  until @x <= time_to_sec(current_time())
  end repeat;
end%
delimiter ;%

RESET BINARY LOGS AND GTIDS;

# Start new connections to let the stmt_cache_size setting take effect
connect(foreground,localhost,root,,);
connect(background,localhost,root,,);
--connection background
--echo # Start running background load for 5 seconds
send call dmlload(5);

--connection foreground
# Using another connection, provoke writing Incident log events by
# exceeding the stmt_cache_size
let $i = 1;
let $incidents = 50;  # Aprox matching runtime of dml_load
let $data= `SELECT CONCAT('"', repeat('a',2000), '"')`;
while ($i <= $incidents)
{
  --echo # i: $i
  --disable_query_log
  --error ER_STMT_CACHE_FULL, ER_ERROR_ON_WRITE
  eval INSERT INTO t1 (c1, data) VALUES ($i,
         CONCAT($data, $data, $data, $data, $data, $data));
  --enable_query_log

  sleep 0.1;
  inc $i;
}
--echo # There should now be $incidents incidents in the binlog

--connection background
--echo # Collect background load result
reap;

--connection default

--echo # Check that binlogs contain Gtid + Incident
--let $i= 1
while ($i <= $incidents)
{
  --let $binlog_file= query_get_value(SHOW BINARY LOGS, Log_name, $i)
  --let $somewhere = 1
  --let $event_sequence= !Gtid_or_anon # Incident
  --source include/rpl/assert_binlog_events.inc

  inc $i;
}

# Cleanup
DROP TABLE t1;
DROP TABLE t2;
DROP PROCEDURE dmlload;
--replace_result $old_max_binlog_stmt_cache_size ORIGINAL_VALUE
eval SET GLOBAL max_binlog_stmt_cache_size= $old_max_binlog_stmt_cache_size;
--replace_result $old_binlog_stmt_cache_size ORIGINAL_VALUE
eval SET GLOBAL binlog_stmt_cache_size= $old_binlog_stmt_cache_size;
--disconnect foreground
--disconnect background
