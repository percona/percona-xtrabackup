## Various regression tests
##
--source include/restart_mysqld.inc
--let $xplugin_disable_ssl_for_x_at_client_side=1
--let $xplugin_cache_x_root=1
--source include/xplugin_preamble.inc
--source include/xplugin_create_user.inc

## Test starts here
--write_file $MYSQL_TMP_DIR/mysqlx-largetest.xpl
-->sql
use test;
create table bla (data json);
-->endsql

-->varfile %JSONDATA_UNESCAPED% %PATH_TO_256kb_JSON_FILE%

# prevent flood from big json data
-->quiet
-->varlet %JSONDATA% %JSONDATA_UNESCAPED%
-->varescape %JSONDATA%
-->varsub %JSONDATA%
-->stmtsql insert into bla values ('%JSONDATA%');
-->recvresult
-->noquiet

-->varsub %JSONDATA_UNESCAPED%
-->sql
select * from bla;
-->endsql

-->sql
drop table bla;
-->endsql


-->vargen %1% . 610000

-->quiet
-->varsub %1%
Mysqlx.Sql.StmtExecute {
    stmt: "select '>%1%!1' as result"
}
-->noquiet

-->recv
-->varsub %1%
-->recv
-->recv
-->recvuntil Mysqlx.Sql.StmtExecuteOk
EOF

--write_file $MYSQL_TMP_DIR/mysqlx-largetest-asio.xpl
-->vargen %1% . 161000000

-->varsub %1%
-->quiet
# lets put the SQL string directly to message, its faster than parsing
# 161MB message by protobuf
-->stmtsql select 1; /* %1% */;
-->noquiet
-->recvresult
EOF

--write_file $MYSQL_TMP_DIR/mysqlx-empty.xpl
EOF

--exec $MYSQLXTEST -ux_root --password='' --file=$MYSQL_TMP_DIR/mysqlx-largetest.xpl -v %PATH_TO_256kb_JSON_FILE%=$MYSQL_TEST_DIR/std_data/256kb.json 2>&1

SET GLOBAL mysqlx_max_allowed_packet=162000000;

--exec $MYSQLXTEST -ux_root --password='' --file=$MYSQL_TMP_DIR/mysqlx-empty.xpl 2>&1
--exec $MYSQLXTEST -ux_root --password='' --file=$MYSQL_TMP_DIR/mysqlx-largetest-asio.xpl 2>&1

## Cleanup
SET GLOBAL mysqlx_max_allowed_packet= DEFAULT;
--source ../include/xplugin_cleanup.inc

