#
# Bug#35686098 Assertion `n < size()' failed in Element_type& Mem_root_array_YY
#
CREATE TABLE t1(
c1 TEXT,
c2 CHAR(255) DEFAULT NULL
);
LOAD DATA INFILE '../../std_data/t1_2cols.csv' INTO TABLE t1 FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n';
ANALYZE TABLE t1;
Table	Op	Msg_type	Msg_text
test.t1	analyze	status	OK
SET optimizer_trace="enabled=on";
SELECT MAX( c1 ) OVER ( ORDER BY c2 ROWS CURRENT ROW ) FROM t1
INTERSECT DISTINCT
SELECT "can't" OR 447938560 FROM t1;
MAX( c1 ) OVER ( ORDER BY c2 ROWS CURRENT ROW )
Warnings:
Warning	1292	Truncated incorrect DOUBLE value: 'can't'
SELECT JSON_PRETTY(JSON_EXTRACT(trace,"$.steps[*].join_execution"))
FROM information_schema.optimizer_trace;
JSON_PRETTY(JSON_EXTRACT(trace,"$.steps[*].join_execution"))
[
  {
    "steps": [
      {
        "materialize for intersect": {
          "steps": [
            {
              "de-duplicate with hash table": {
                "steps": [
                  {
                    "sorting_table": "t1",
                    "filesort_summary": {
                      "key_size": 4089,
                      "row_size": 70653,
                      "sort_mode": "<varlen_sort_key, packed_additional_fields>",
                      "num_rows_found": 501,
                      "sort_algorithm": "std::sort",
                      "memory_available": 262144,
                      "peak_memory_used": "elided",
                      "num_rows_estimate": "elided",
                      "max_rows_per_buffer": 3,
                      "num_initial_chunks_spilled_to_disk": "elided"
                    },
                    "filesort_execution": [],
                    "filesort_information": [
                      {
                        "direction": "asc",
                        "expression": "`t1`.`c2`"
                      }
                    ],
                    "filesort_priority_queue_optimization": {
                      "cause": "not applicable (no LIMIT)",
                      "usable": false
                    }
                  },
                  {
                    "spill to disk initiated": {
                      "chunk sets": 1,
                      "chunk files": "elided"
                    }
                  }
                ]
              }
            }
          ],
          "select#": 1
        }
      },
      {
        "materialize for intersect": {
          "steps": [
            {
              "de-duplicate with hash table": {
                "steps": []
              }
            }
          ],
          "select#": 2
        }
      }
    ]
  }
]
SET optimizer_trace=default;
DROP TABLE t1;
#
# Bug#35970620 hash_set_operations optimizer off assertion error
#
PREPARE p0 FROM '(SELECT 3 AS three) EXCEPT (SELECT 1)';
SET SESSION optimizer_switch = 'hash_set_operations=off';
SET SESSION optimizer_trace = 'enabled=on';
EXECUTE p0;
three
3
SELECT JSON_PRETTY(JSON_EXTRACT(trace,
'$.steps[*].join_execution.steps[*]."materialize for except"')) AS j
FROM information_schema.OPTIMIZER_TRACE;
j
[
  {
    "steps": [
      {
        "de-duplicate with index": {
          "steps": []
        }
      }
    ],
    "select#": 1
  },
  {
    "steps": [
      {
        "de-duplicate with index": {
          "steps": []
        }
      }
    ],
    "select#": 2
  }
]
SET SESSION optimizer_switch = 'hash_set_operations=on';
EXECUTE p0;
three
3
SELECT JSON_PRETTY(JSON_EXTRACT(trace,
'$.steps[*].join_execution.steps[*]."materialize for except"')) AS j
FROM information_schema.OPTIMIZER_TRACE;
j
[
  {
    "steps": [
      {
        "de-duplicate with hash table": {
          "steps": []
        }
      }
    ],
    "select#": 1
  },
  {
    "steps": [
      {
        "de-duplicate with hash table": {
          "steps": []
        }
      }
    ],
    "select#": 2
  }
]
SET SESSION optimizer_switch = 'hash_set_operations=off';
EXECUTE p0;
three
3
SELECT JSON_PRETTY(JSON_EXTRACT(trace,
'$.steps[*].join_execution.steps[*]."materialize for except"')) AS j
FROM information_schema.OPTIMIZER_TRACE;
j
[
  {
    "steps": [
      {
        "de-duplicate with index": {
          "steps": []
        }
      }
    ],
    "select#": 1
  },
  {
    "steps": [
      {
        "de-duplicate with index": {
          "steps": []
        }
      }
    ],
    "select#": 2
  }
]
SET SESSION optimizer_switch = 'hash_set_operations=on';
EXECUTE p0;
three
3
SELECT JSON_PRETTY(JSON_EXTRACT(trace,
'$.steps[*].join_execution.steps[*]."materialize for except"')) AS j
FROM information_schema.OPTIMIZER_TRACE;
j
[
  {
    "steps": [
      {
        "de-duplicate with hash table": {
          "steps": []
        }
      }
    ],
    "select#": 1
  },
  {
    "steps": [
      {
        "de-duplicate with hash table": {
          "steps": []
        }
      }
    ],
    "select#": 2
  }
]
SET SESSION optimizer_switch = 'hash_set_operations=off';
PREPARE p0 FROM '(SELECT 3 AS three) EXCEPT (SELECT 1)';
SET SESSION optimizer_switch = 'hash_set_operations=on';
EXECUTE p0;
three
3
SELECT JSON_PRETTY(JSON_EXTRACT(trace,
'$.steps[*].join_execution.steps[*]."materialize for except"')) AS j
FROM information_schema.OPTIMIZER_TRACE;
j
[
  {
    "steps": [
      {
        "de-duplicate with hash table": {
          "steps": []
        }
      }
    ],
    "select#": 1
  },
  {
    "steps": [
      {
        "de-duplicate with hash table": {
          "steps": []
        }
      }
    ],
    "select#": 2
  }
]
SET SESSION optimizer_switch = 'hash_set_operations=off';
EXECUTE p0;
three
3
SELECT JSON_PRETTY(JSON_EXTRACT(trace,
'$.steps[*].join_execution.steps[*]."materialize for except"')) AS j
FROM information_schema.OPTIMIZER_TRACE;
j
[
  {
    "steps": [
      {
        "de-duplicate with index": {
          "steps": []
        }
      }
    ],
    "select#": 1
  },
  {
    "steps": [
      {
        "de-duplicate with index": {
          "steps": []
        }
      }
    ],
    "select#": 2
  }
]
SET SESSION optimizer_switch = 'hash_set_operations=on';
EXECUTE p0;
three
3
SELECT JSON_PRETTY(JSON_EXTRACT(trace,
'$.steps[*].join_execution.steps[*]."materialize for except"')) AS j
FROM information_schema.OPTIMIZER_TRACE;
j
[
  {
    "steps": [
      {
        "de-duplicate with hash table": {
          "steps": []
        }
      }
    ],
    "select#": 1
  },
  {
    "steps": [
      {
        "de-duplicate with hash table": {
          "steps": []
        }
      }
    ],
    "select#": 2
  }
]
SET SESSION optimizer_switch = 'hash_set_operations=off';
EXECUTE p0;
three
3
SELECT JSON_PRETTY(JSON_EXTRACT(trace,
'$.steps[*].join_execution.steps[*]."materialize for except"')) AS j
FROM information_schema.OPTIMIZER_TRACE;
j
[
  {
    "steps": [
      {
        "de-duplicate with index": {
          "steps": []
        }
      }
    ],
    "select#": 1
  },
  {
    "steps": [
      {
        "de-duplicate with index": {
          "steps": []
        }
      }
    ],
    "select#": 2
  }
]
DROP PREPARE p0;
SET SESSION optimizer_trace = 'enabled=default';
SET SESSION optimizer_switch = 'hash_set_operations=default';
#
# Bug#36307622 Wrong result from query with WHERE integer IN (SELECT 2 EXCEPT SELECT 4)
#
CREATE TABLE c (
pk int NOT NULL AUTO_INCREMENT,
col_datetime_key datetime DEFAULT NULL,
col_varchar_key varchar(1) DEFAULT NULL,
PRIMARY KEY (pk),
KEY idx_c_col_datetime_key (col_datetime_key),
KEY idx_c_col_varchar_key (col_varchar_key)
);
INSERT INTO c VALUES (1,'2022-10-30 08:18:58','o');
INSERT INTO c VALUES (2,'1998-01-19 17:27:57','䋠');
INSERT INTO c VALUES (3,'2015-09-01 16:34:18','X');
INSERT INTO c VALUES (4,'2020-08-29 15:09:33','m');
INSERT INTO c VALUES (5,'2018-07-01 22:36:45','d');
INSERT INTO c VALUES (6,'2028-02-07 02:02:10','q');
INSERT INTO c VALUES (7,'2016-02-04 17:29:46','8');
INSERT INTO c VALUES (8,'2037-07-02 21:02:05','0');
INSERT INTO c VALUES (9,'1970-08-03 04:25:41','旘');
INSERT INTO c VALUES (10,'1973-07-18 13:38:35','v');
INSERT INTO c VALUES (11,'1990-08-03 14:18:01','υ');
INSERT INTO c VALUES (12,'2036-07-05 20:41:55','ǆ');
INSERT INTO c VALUES (13,'2035-02-11 10:59:22','䩈');
INSERT INTO c VALUES (14,'1992-10-24 00:44:20','L');
INSERT INTO c VALUES (15,'1995-05-04 07:35:45','W');
INSERT INTO c VALUES (16,'2027-01-15 17:09:03','η');
INSERT INTO c VALUES (17,'1998-02-15 07:48:55','V');
INSERT INTO c VALUES (18,'1998-02-16 17:42:54','᥋');
INSERT INTO c VALUES (19,'1991-03-04 15:36:40','D');
INSERT INTO c VALUES (20,'1973-06-24 15:12:44','O');
SELECT pk FROM c WHERE pk IN (SELECT 2 EXCEPT SELECT 4);
pk
2
SELECT pk FROM c WHERE pk IN (SELECT 2 EXCEPT SELECT 4) ORDER BY pk;
pk
2
DROP TABLE c;
#
# Bug#36332697 IN predicate containing EXCEPT ALL set operation gives wrong result
#
CREATE TABLE t(i INTEGER);
INSERT INTO t VALUES (1), (2), (3), (4), (5);
ANALYZE TABLE t;
Table	Op	Msg_type	Msg_text
test.t	analyze	status	OK
# This results in a single row of 2.
(SELECT 2 AS two UNION ALL SELECT 2)
EXCEPT ALL
SELECT 2;
two
2
# Before the fix, this same set inside an IN predicate used to
# return an empty result set even though one of the rows in t
# has the value 2.
SELECT i FROM t WHERE i IN ( (SELECT 2 UNION ALL SELECT 2)
EXCEPT ALL
SELECT 2 );
i
2
EXPLAIN ANALYZE SELECT i FROM t WHERE i IN ( (SELECT 2 UNION ALL SELECT 2)
EXCEPT ALL
SELECT 2 );
EXPLAIN
-> Filter: <in_optimizer>(t.i,<exists>(select #2))  (...) (actual rows=1 loops=1)
    -> Table scan on t  (...) (actual rows=5 loops=1)
    -> Select #2 (subquery in condition; dependent)
        -> Limit: 1 row(s)  (...) (actual rows=0.2 loops=5)
            -> Table scan on <except temporary>  (...) (actual rows=0.2 loops=5)
                -> Except all materialize  (...) (actual rows=0.2 loops=5)
                    -> Table scan on <union temporary>  (...) (actual rows=0.4 loops=5)
                        -> Union all materialize  (...) (actual rows=0.4 loops=5)
                            -> Filter: (<cache>(t.i) = <ref_null_helper>(2))  (...) (actual rows=0.2 loops=5)
                                -> Rows fetched before execution  (...) (actual rows=1 loops=5)
                            -> Filter: (<cache>(t.i) = <ref_null_helper>(2))  (...) (actual rows=0.2 loops=5)
                                -> Rows fetched before execution  (...) (actual rows=1 loops=5)
                    -> Filter: (<cache>(t.i) = <ref_null_helper>(2))  (...) (actual rows=0.25 loops=4)
                        -> Rows fetched before execution  (...) (actual rows=1 loops=4)

# Using tmp table index based de-duplication didn't help; same issue
SET optimizer_switch="hash_set_operations=off";
SELECT i FROM t WHERE i IN ( (SELECT 2 UNION ALL SELECT 2)
EXCEPT ALL
SELECT 2 );
i
2
EXPLAIN ANALYZE SELECT i FROM t WHERE i IN ( (SELECT 2 UNION ALL SELECT 2)
EXCEPT ALL
SELECT 2 );
EXPLAIN
-> Filter: <in_optimizer>(t.i,<exists>(select #2))  (...) (actual rows=1 loops=1)
    -> Table scan on t  (...) (actual rows=5 loops=1)
    -> Select #2 (subquery in condition; dependent)
        -> Limit: 1 row(s)  (...) (actual rows=0.2 loops=5)
            -> Table scan on <except temporary>  (...) (actual rows=0.2 loops=5)
                -> Except all materialize  (...) (actual rows=0.2 loops=5)
                    -> Table scan on <union temporary>  (...) (actual rows=0.4 loops=5)
                        -> Union all materialize  (...) (actual rows=0.4 loops=5)
                            -> Filter: (<cache>(t.i) = <ref_null_helper>(2))  (...) (actual rows=0.2 loops=5)
                                -> Rows fetched before execution  (...) (actual rows=1 loops=5)
                            -> Filter: (<cache>(t.i) = <ref_null_helper>(2))  (...) (actual rows=0.2 loops=5)
                                -> Rows fetched before execution  (...) (actual rows=1 loops=5)
                    -> Filter: (<cache>(t.i) = <ref_null_helper>(2))  (...) (actual rows=1 loops=1)
                        -> Rows fetched before execution  (...) (actual rows=1 loops=1)

SET optimizer_switch="hash_set_operations=default";
DROP TABLE t;
#
# Bug#36075756 ASAN crash on
# MaterializeIterator<Profiler>::load_HF_row_into_hash_map()
#
CREATE TABLE t1 (c1 INT, c2 TIME);
INSERT INTO t1 VALUES (4,'09:29:08'), (NULL,'19:11:10'), (2,'11:57:26'),
(6,'00:39:46'), (6,'03:28:15'),    (8,'06:44:18'),
(2,'14:36:39'), (6,'18:42:45'),    (8,'02:57:29'),
(3,'16:46:13');
CREATE VIEW view_t1 AS SELECT * FROM t1;
# Used to assert with -DWITH_DEBUG=1 -DWITH_ASAN=1 (both required)
# build on Oracle Linux Server 8
SELECT SUBSTRING(t.rep, 1, 4) AS sub, LENGTH(t.rep) AS len
FROM
( SELECT REPEAT(c1, c2) AS rep FROM view_t1
EXCEPT DISTINCT
SELECT DISTINCT RANK() OVER () FROM t1 ) AS t
ORDER BY len;
sub	len
NULL	NULL
6666	3946
8888	25729
6666	32815
8888	64418
4444	92908
2222	115726
2222	143639
3333	164613
6666	184245
DROP VIEW view_t1;
DROP TABLE t1;
#
# Bug#36695371 wrong merge of derived table if unary nested
#
CREATE TABLE t(pka INT NOT NULL AUTO_INCREMENT, a1 INT, a2 INT, PRIMARY KEY(pka));
INSERT INTO t(a1,a2) VALUES (1,3), (2,5), (3,7), (4,8), (5,9), (6,10), (7,11);
INSERT INTO t(a1,a2) SELECT a1,a2 FROM t;
SELECT * FROM ( (SELECT a1,a2 FROM t ORDER BY a1,a2 ASC)
ORDER BY a2/a1 DESC LIMIT 7 ) AS derived;
a1	a2
1	3
1	3
2	5
2	5
3	7
3	7
4	8
EXPLAIN FORMAT=tree SELECT * FROM ( (SELECT a1,a2 FROM t ORDER BY a1,a2 ASC)
ORDER BY a2/a1 DESC LIMIT 7 ) AS derived;
EXPLAIN
-> Table scan on derived  (rows=7)
    -> Materialize  (rows=7)
        -> Limit: 7 row(s)  (rows=7)
            -> Sort: (a2 / a1) DESC, limit input to 7 row(s) per chunk  (rows=7)
                -> Table scan on <result temporary>  (rows=14)
                    -> Temporary table  (rows=14)
                        -> Table scan on t  (rows=14)

CREATE VIEW v AS SELECT * FROM ( (SELECT a1,a2 FROM t ORDER BY a1,a2 ASC)
ORDER BY a2/a1 DESC LIMIT 7 ) AS derived;
SELECT * FROM v;
a1	a2
1	3
1	3
2	5
2	5
3	7
3	7
4	8
EXPLAIN FORMAT=tree SELECT * FROM v;
EXPLAIN
-> Table scan on derived  (rows=7)
    -> Materialize  (rows=7)
        -> Limit: 7 row(s)  (rows=7)
            -> Sort: (a2 / a1) DESC, limit input to 7 row(s) per chunk  (rows=7)
                -> Table scan on <result temporary>  (rows=14)
                    -> Temporary table  (rows=14)
                        -> Table scan on t  (rows=14)

DROP VIEW v;
DROP TABLE t;
#
# Bug#36739383 Assertion `false' materialize_iterator::SpillState::
#              read_next_row_secondary_over
#
CREATE TABLE t(i int, b LONGTEXT);
INSERT INTO t VALUES (0, REPEAT('x', 120000)),
/* next row is too large on its own, drop spill
handling entirely revert to indexed tmp table
de-duplication */
(0, REPEAT('y', @@set_operations_buffer_size)),
(0, REPEAT('z', 12000));
ANALYZE TABLE t;
Table	Op	Msg_type	Msg_text
test.t	analyze	status	OK
SET optimizer_trace='enabled=on';
SELECT LENGTH(b) FROM (SELECT * FROM t INTERSECT SELECT * FROM t) derived;
LENGTH(b)
12000
120000
262144
SELECT JSON_PRETTY(JSON_EXTRACT(
trace,
'$.steps[*].join_execution.steps[*]."materialize for intersect"')) AS info
FROM information_schema.OPTIMIZER_TRACE AS t;
info
[
  {
    "steps": [
      {
        "de-duplicate with hash table": {
          "steps": [
            {
              "spill handling not attempted due to large row, reverting to index": {
                "steps": [
                  {
                    "creating_tmp_table": {
                      "tmp_table_info": {
                        "table": "derived",
                        "columns": 4,
                        "location": "TempTable",
                        "key_length": 8,
                        "row_length": 33,
                        "unique_constraint": true,
                        "makes_grouped_rows": false,
                        "in_plan_at_position": 0,
                        "cannot_insert_duplicates": true
                      }
                    }
                  }
                ]
              }
            }
          ]
        }
      }
    ],
    "select#": 2
  },
  {
    "steps": [
      {
        "de-duplicate with index": {
          "steps": []
        }
      }
    ],
    "select#": 3
  }
]
TRUNCATE t;
INSERT INTO t VALUES (0, REPEAT('x', 12000)),
/* next row is too large because we can't fit two
                        such in hash map drop spill handling entirely
                        revert to indexed tmp table de-duplication */
                     (0, REPEAT('x', 140000)),
                     (0, REPEAT('z', 120000));
ANALYZE TABLE t;
Table	Op	Msg_type	Msg_text
test.t	analyze	status	OK
SELECT LENGTH(b) FROM (SELECT * FROM t INTERSECT SELECT * FROM t) derived;
LENGTH(b)
12000
120000
140000
SELECT JSON_PRETTY(JSON_EXTRACT(
trace,
'$.steps[*].join_execution.steps[*]."materialize for intersect"')) AS info
FROM information_schema.OPTIMIZER_TRACE AS t;
info
[
  {
    "steps": [
      {
        "de-duplicate with hash table": {
          "steps": [
            {
              "spill to disk initiated": {
                "chunk sets": 1,
                "chunk files": 32
              }
            }
          ]
        }
      }
    ],
    "select#": 2
  },
  {
    "steps": [
      {
        "de-duplicate with hash table": {
          "steps": []
        }
      }
    ],
    "select#": 3
  }
]
SET optimizer_trace='enabled=default';
DROP TABLE t;
